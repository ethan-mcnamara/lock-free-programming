# Preliminary Research on Lock-Free Programming

## Introduction
At the suggestion of Dr. Chester, three video lectures on the topic of lock-free programming were analyzed with the results summarized below. The purpose of the analysis was to determine the purpose of lock-free programming, common design patterns used in lock-free programming, the common pitfalls that arise from this programming style, and why this style of programming can often result in an onerous burden being placed on the developers.

## Video Lectures Analyzed
The three video lectures analyzed can be accessed through the following links. Throughout the below analysis, reference to these lectures will be done in the form of *Video #1/#2/#3* rather than the titles of the lectures for reasons of conciseness and clarity. 
1. Introduction to Lock-free Programming - Tony van Eerd (Video #1)
  * [Video lecture link](https://www.youtube.com/watch?v=RWCadBJ6wTk "Introduction to Lock-free Programming - Tony van Eerd") 
2. Lock-Free Programming (or, Juggling Razor Blades) - Herb Sutter (Video #2)
  * [Video lecture link (Part I)](https://www.youtube.com/watch?v=c1gO9aB9nbs "Lock-Free Programming (or, Juggling Razor Blades) - Herb Sutter Part I")
  * [Video lecture link (Part II)](https://www.youtube.com/watch?v=CmxkPChOcvw "Lock-Free Programming (or, Juggling Razor Blades) - Herb Sutter Part II")
3. Live Lock-Free or Deadlock (Practical Lock-free Programming) - Fedor Pikus (Video #3)
  * [Video lecture link (Part I)](https://www.youtube.com/watch?v=lVBvHbJsg5Y "Live Lock-Free or Deadlock (Practical Lock-free Programming) - Fedor Pikus Part I")
  * [Video lecture link (Part II)](https://www.youtube.com/watch?v=1obZeHnAwz4 "Live Lock-Free or Deadlock (Practical Lock-free Programming) - Fedor Pikus Part II")
4. Nonblocking data structures - Michael Scott (Video #4)
  * [Video lecture link (Part I)](https://youtu.be/9XAx279s7gs "Michael Scott — Nonblocking data structures. Part 1.")
  * [Video lecture link (Part II)](https://youtu.be/cQIktrroRL0 "Michael Scott — Nonblocking data structures. Part 2.")

## Purpose of Lock-Free Programming
Lock-free programming is designed to improve the performance of multi-threaded memory-bound applications. In this case, a memory-bound application is one for which the largest bottlenecks exist in accessing data in memory. While lock-free programming can be applied to single-threaded applications, the first step in this approach would be to convert the single-threaded program into a multi-threaded program and then apply lock-free techniques so it is simpler to apply the definition solely to multi-threaded applications.

Lock-free techniques, like mutexes and locks, aim to eliminate race conditions from multi-threaded applications. Race conditions can occur when two or more threads are accessing a single variable simultaneously and the result of the program will depend on the essentially random nature of which thread completes its operations first. The traditional approach to race conditions has been to incorporate locks that lock a variable during the time in which a thread is accessing said variable and unlock it after the thread has completed its work. While this works well in a simple example, problems arrise when there are several locks in a program and two threads can each hold the lock the other desires but neither is willing to release the lock they hold, leading to a situation commonly known as a *deadlock*. 

Additionally, as van Eerd speaks to in *Video #1*, there can exist race conditions in places it would not seem possible for a race condition to exist, such as between checking a variable in an `if` condition and writing to said variable on the next line. These race conditions are due to the reordering and scheduling done by the operating system of the CPU, which again can lead to undesired results.

Lock-free programming, true to its name, typically does not use locks in its implementations. Instead, atomic compare-and-swap (CAS) operations are used, often inside `while` loops, to determine whether a value of a variable read at an earlier time is still equal to the variable's current value before writing to said variable. The common implementation will involve a `do-while` loop where inside to the `do` statement the value is read and stored in a temporary variable before writing to another temporary variable the desired new value of the variable. Inside the `while` statement a CAS function is called that checks whether the value read and stored is still equal to the variable in memory in which case the new desired value is written and breaks from the loop and if not the loop reiterates.

This lock-free approach is superior to the mutex approach in that it guarantees that at least one thread will at all time be making progress, i.e. there exists no possibility of a deadlock where no threads are making any progress. While there are some other considerations that need to be made, that is the common rationale for choosing a lock-free approach compared to an approach using locks.

## Common Design Patterns and Techniques in Lock-Free Programming
As mentioned in the above sections, and indeed in all three video lectures, the main design technique of lock-free programming is to use a CAS function call. It is important to remember however, that the CAS function must be atomic in its implementation or the validity of the program no longer holds. Because the CAS function is essentially two operations, the first being a conditional to check whether the two values are equal with the second being a write operation, if these are not atomic, this is equal to the example mentioned in *Video #1* where an `if` condition is written on the line directly above a write instruction. Without atomicity, it is impossible to say definitively whether or not the value read has been updated at the time of writing.

Also, due to the nature of the CAS function van Eerd explains in *Video #1* that should manipulation of multiple variables be required in an atomic nature, the CAS function is not the ideal tool due to the fact that it is only considering the value of a single variable at a time and cannot support the examination of multiple variables at once. Should the atomic manipulation of multiple variables be required, each of Sutter (*Video #2*) and Pikus (*Video #3*) had suggestions for maintaining the use of the CAS function without sacrificing the program's validity. Sutter's sugestion, which is likely the one most developers will first consider, is to wrap the variables within a `struct` or `class` and manipulate the abstracted data structure rather than the primitive data structures. Sutter warned that while this approach does work well for objects of smaller size, he explained that when these objects are sufficiently large, locks are used by the CPU when accessing this data as they may require multiple cache reads to fully bring into main memory which may cause unintended performance degredation. Pikus's solution, which is arguably more complex and narrow in its use cases, is to pack smaller variables into a single 64-bit word which can easily be manipulated atomically. This approach only applies when multiple variables smaller than 64-bits are being manipulated and will require custom logic for manipulating the variables but may be the ideal approach for some programs. 

## Why is Lock-Free Programming so Hard and is it Worth the Hastle?
Lock-free programming is an optimization technique and as a result, is not a style of programming with which many developers are familiar. If the goal of the developer is to develop an application in a reasonable amount of time, very few would willingly incorporate lock-free techniques from the outset as this will place an undue burden on the development of the application. As a result, while lock-free programming is a technique that can be difficult to incorporate, the main reason it is viewed with such trepidation is a lack of a solid understanding of the technique's benefits and implementation details.

That being said, even if every software engineering new grad had been provided an in-depth look into lock-free programming, it is unlikely most new applications would incorporate this programming technique due to the technical difficulties that can result from developing and debugging lock-free applications. As Pikus mentioned in *Video #3*, there are a number of considerations that must be made when considering implementing lock-free techniques into an existing program. Firstly, poor application performance should be the primary reason for implementing lock-free programming. Some applications run on hardware or operate in environments where performance is less of a factor and as a result the development cost to create a lock-free implementation will not net a positive return on investment. Assuming performance is the driving factor, lock-free programming is typically only the ideal approach when the number of shared variables is minimal. As Pikus explained, with a large volume of shared variables, the complexity of lock-free algorithms increases significantly, potentially to a level where the performance gains achieved by the lock-free implementation are outweighed by the strain the data synchronization costs are placing on the program. Overall, if the conditions are met such that a lock-free approach is the ideal solution and a development team exists such that this change will not place an overly burdensome task on their plates, lock-free programming is likely to reap the rewards it promises and be worth the hassle of development and debugging such a program.

The answer for first half of the question acting as a subtitle for this section can be determined by examining the common problems developers experience with multi-threaded applications, lock-free or otherwise. Multi-threaded applications are notoriously difficult to debug and test due to the sometimes unpredictable nature of their instructions. The situation can also occur where a bug does not exist in development or testing but then appears suddenly once deployed to production due a singular race condition having not yet occurred to that point. The common approach to these issues is to use mutexes or locks, but of course these bring their own problems that require management. Lock-free programming takes these impediments and incorporates more complex methods of dealing with them than simple locks that are acquired before a critical section and released afterwards. Instead, atomic instructions with which most developers have less familiarity are used. This approach to solving multi-threaded programs is not necessarily more difficult than using locks, but the lack of familiarity with the tools available, combined with the already-present difficulties of multi-threaded programming breeds a programming style that is commonly feared despite the benefits of the technique and its relative simplicity when examined deeper. 

## Conclusion
Lock-free programming is a technique that can provide a significant benefit to an application's performance, provided it is implemented properly and the proper considerations are made to ensure that lock-free programming is indeed the ideal optimization technique for the problem at hand. While it does avoid many of the pitfalls incurred by other multi-threaded programming styles, it does come with its own that must be handled accordingly to guarantee the application under development is running efficiently and properly.
